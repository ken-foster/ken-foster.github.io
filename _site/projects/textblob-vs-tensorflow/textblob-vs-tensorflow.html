<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Textblob vs Tensorflow for Sentiment Analysis | Home</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Textblob vs Tensorflow for Sentiment Analysis" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A portfolio website for Kenneth Foster" />
<meta property="og:description" content="A portfolio website for Kenneth Foster" />
<link rel="canonical" href="http://localhost:4000/projects/textblob-vs-tensorflow/textblob-vs-tensorflow.html" />
<meta property="og:url" content="http://localhost:4000/projects/textblob-vs-tensorflow/textblob-vs-tensorflow.html" />
<meta property="og:site_name" content="Home" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Textblob vs Tensorflow for Sentiment Analysis" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"A portfolio website for Kenneth Foster","headline":"Textblob vs Tensorflow for Sentiment Analysis","url":"http://localhost:4000/projects/textblob-vs-tensorflow/textblob-vs-tensorflow.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Home" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Home</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Textblob vs Tensorflow for Sentiment Analysis</h1>
  </header>

  <div class="post-content">
    <h1 id="textblob-vs-tensorflow-for-sentiment-analysis">Textblob vs Tensorflow for Sentiment Analysis</h1>

<p>From the <a href="https://textblob.readthedocs.io/en/dev/">official TextBlob documentation</a>:</p>
<blockquote>
  <p><strong>TextBlob</strong> is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.</p>
</blockquote>

<p>Textblob is indeed, a convenient package. I’m going to rigorously compare its sentiment analysis capabilities against a simple neural network model using the tensorflow library. What I find is that TextBlob’s main draw is that it requires very little coding and no training data, as its accuracy is lacking compared to a neural net with <strong>A.</strong> A publicly available text embedding model and <strong>B.</strong> Specific training data for the task at hand.</p>

<p>For this comparison, I use a sample of Amazon product reviews, originally hosted Stanford Network Analysis Project (SNAP), trimmed to a balanced subset by Zheng et al. at NYU, and finally posted for easy access to Kaggle by user Kritanjali Jain <a href="https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews">here</a>.</p>

<p>Starting with a relatively small sample of observations (for practical reasons of computing time), I’ll experiment with 6 different combinations of internal activation functions and optimizers. I record and compare the computational speed and prediction accuracy and use these metrics to identify a preferred specification. Finally, I’ll run the best performing model one final time on the full dataset and evaluate its performance.</p>

<p><strong><em>Sections:</em></strong></p>
<ul>
  <li><a href="#housekeeping">Housekeeping</a></li>
  <li><a href="#load-data">Load Data</a></li>
  <li><a href="#textblob-benchmark">TextBlob Benchmark</a></li>
  <li><a href="#neural-network-experiments">Neural Network Experiments</a></li>
  <li><a href="#final-model">Final Model</a></li>
</ul>

<blockquote>
  <p>This notebook is an adaptation of a Machine Learning coursework project for the Master’s in Quantitative Economics program at UCLA. The original report, done in collaboration with two other students, can downloaded as a .pdf file <a href="https://github.com/ken-foster/ken-foster.github.io/raw/main/files/Textblob%20vs%20TensorFlow.pdf" download="">here</a>.<br /><br />The final version of this script was run as a Kaggle Notebook, using their free P100 GPU accelerator. If you’d like to replicate it, I recommend creating a copy using Kaggle from <a href="https://www.kaggle.com/code/kfoster150/textblob-vs-tensorflow-for-sentiment-analysis">here</a>.</p>
</blockquote>

<h1 id="housekeeping">Housekeeping</h1>
<h2 id="kaggle-logic">Kaggle Logic</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># If running on Kaggle, must install TextBlob
# inside the notebook
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">r</span><span class="s">"/kaggle"</span><span class="p">):</span>
    <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">"PIP_ROOT_USER_ACTION"</span><span class="p">]</span><span class="o">=</span><span class="s">"ignore"</span>
    <span class="n">os</span><span class="p">.</span><span class="n">system</span><span class="p">(</span><span class="s">"pip install textblob -q"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="load-libraries">Load Libraries</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Basic
</span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">timeit</span>

<span class="c1"># Third-Party
</span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="n">hub</span>
<span class="kn">import</span> <span class="nn">textblob</span>
</code></pre></div></div>

<h2 id="matplotlib-options">Matplotlib Options</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Kaggle uses an older version of matplotlib 
# with a different name for the `seaborn` style
</span><span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">r</span><span class="s">"/kaggle"</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">"seaborn"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">"seaborn-v0_8"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"figure.figsize"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"legend.facecolor"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"white"</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"legend.frameon"</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">"legend.framealpha"</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span>
</code></pre></div></div>

<h1 id="load-data">Load Data</h1>
<h2 id="read-from-file">Read from file</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define function to .csv from Kaggle
</span><span class="k">def</span> <span class="nf">read_amazon_reviews</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span><span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
                     <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">,</span><span class="s">"text"</span><span class="p">],</span>
                     <span class="n">engine</span><span class="o">=</span><span class="s">"c"</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="k">return</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>


<span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="sa">r</span><span class="s">"/kaggle"</span><span class="p">):</span>
    <span class="n">data_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s">"/kaggle/input/amazon-reviews/"</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># May change depending on where you've saved these files
</span>    <span class="n">data_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s">"/data/original/"</span> 

<span class="k">print</span><span class="p">(</span><span class="s">"Reading Training Data"</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">read_amazon_reviews</span><span class="p">(</span><span class="n">data_path</span> <span class="o">+</span> <span class="s">"train.csv"</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Reading Testing Data"</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">read_amazon_reviews</span><span class="p">(</span><span class="n">data_path</span> <span class="o">+</span> <span class="s">"test.csv"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Reading Training Data
Reading Testing Data
</code></pre></div></div>

<h2 id="create-validation-set">Create Validation Set</h2>
<p>Originally, the data is split into train and test sets. I create one more, a validation set with the same number of observations as the test set, by splitting some data off from the train set.</p>

<p>Now there are 3 sets of data that will be applied to our final neural network model:</p>
<ul>
  <li><strong>Train</strong>: For training the network</li>
  <li><strong>Valid</strong>: To check for overfitting while training the network</li>
  <li><strong>Test</strong>: For doing final tests of accuracy and class recall.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Get number of test observations 
# (400,000)
</span><span class="n">n</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># To validate during training
</span><span class="n">valid</span> <span class="o">=</span> <span class="n">train</span><span class="p">[:</span><span class="n">n</span><span class="p">].</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> 

<span class="c1"># Re-initialize train object w/out validation observations
</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">n</span><span class="p">:].</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> 
</code></pre></div></div>

<h2 id="balance-checking">Balance Checking</h2>
<p>We check that each class, positive and negative, is mostly equally represented in the subsets created.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">valid</span><span class="p">,</span> <span class="n">test</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0    0.501462
1    0.498538
Name: polarity, dtype: float64
1    0.50517
0    0.49483
Name: polarity, dtype: float64
1    0.5
0    0.5
Name: polarity, dtype: float64
</code></pre></div></div>

<p>Each set has about half positive, and half negative reviews.</p>

<h1 id="textblob-benchmark">Textblob Benchmark</h1>
<p>As a general use tool, TextBlob is extremely easy to use. A beginner in the python coding language could run it with minimal difficulties. Textblob is pre-trained and weights for different text inputs cannot be modified, so we go straight to the testing step, and copy the <code class="language-plaintext highlighter-rouge">test</code> set object for this purpose.</p>

<p>When Textblob is evaluating text for sentiment, it returns a value between -1 and 1 for negative and positive respectively. Because of this, we’ll create a new dataframe where the outcome variable matches this pattern, rather than 0 and 1 for negative and positive</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define function to return the polarity/probability 
# of text as predicted by Textblob
</span><span class="k">def</span> <span class="nf">get_textblob_probability</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span><span class="p">(</span><span class="n">textblob</span><span class="p">.</span><span class="n">TextBlob</span><span class="p">(</span><span class="n">text</span><span class="p">).</span><span class="n">sentiment</span><span class="p">.</span><span class="n">polarity</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Copy test set
</span><span class="n">tb</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># textblob returns -1,1 for neg,pos reviews
</span><span class="n">tb</span><span class="p">[</span><span class="s">"true"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">tb</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> 

<span class="c1"># Drop original column "polarity" since this is
# superseded by column "true" for this purpose
</span><span class="n">tb</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">"polarity"</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Get TextBlob predictions
</span><span class="n">start</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">tb</span><span class="p">[</span><span class="s">"prob"</span><span class="p">]</span> <span class="o">=</span> <span class="n">tb</span><span class="p">[</span><span class="s">"text"</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="n">get_textblob_probability</span><span class="p">)</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Calculate running time
</span><span class="n">running_time</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span>

<span class="c1"># Print Results and example
</span><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"time to run: </span><span class="si">{</span><span class="n">running_time</span><span class="o">/</span><span class="mi">60</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> minutes"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">tb</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s"> observations"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Sample of probabilities:"</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">tb</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">).</span><span class="n">head</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>time to run: 3.78 minutes
400000 observations

Sample of probabilities:
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>true</th>
      <th>prob</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>75526</th>
      <td>Such great songs...."Yer Blues," "Glass Onion,...</td>
      <td>1</td>
      <td>0.106250</td>
    </tr>
    <tr>
      <th>370505</th>
      <td>This item does not smell right. I have purchas...</td>
      <td>-1</td>
      <td>0.178571</td>
    </tr>
    <tr>
      <th>383810</th>
      <td>I found this video enough good to refresh my m...</td>
      <td>1</td>
      <td>0.200000</td>
    </tr>
    <tr>
      <th>208171</th>
      <td>Good album, especially song 4. They need to in...</td>
      <td>1</td>
      <td>0.244444</td>
    </tr>
    <tr>
      <th>81420</th>
      <td>I've read Asimov's later robot novels, which w...</td>
      <td>-1</td>
      <td>-0.004804</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="thresholds-for-textblob">Thresholds for TextBlob</h2>
<p>By default, a negative value (less than 0.0) from TextBlob should mean that the text had a negative sentiment, but this is not a given. For example, if the results are too “optimistic”, meaning too many observations are predicted as being positive, we may adjust our threshold to consider anything under 0.10 or 0.20 to be a bad sentiment. We create a plot showing how well we detect different sentiments depending on this threshold.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create numpy array of thresholds
</span><span class="n">thresholds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.51</span><span class="p">,</span><span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">).</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Initialize empty lists for accuracy,
# positive class recall and negative 
# class recall
</span><span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">pos_recalls</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">neg_recalls</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Using a loop, populate empty lists
</span><span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="p">:</span>
    
    <span class="c1"># Get prediction conditional on threshold
</span>    <span class="n">tb_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">tb</span><span class="p">[</span><span class="s">"prob"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Get difference between prediction and ground truth
</span>    <span class="c1"># Where difference == 0, the prediction was accurate
</span>    <span class="n">difference</span> <span class="o">=</span> <span class="n">tb_pred</span> <span class="o">-</span> <span class="n">tb</span><span class="p">[</span><span class="s">"true"</span><span class="p">]</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">difference</span><span class="p">.</span><span class="n">value_counts</span><span class="p">()</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">tb</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Get positive recall
</span>    <span class="n">pos_num</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">tb</span><span class="p">[</span><span class="s">"true"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">tb_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">pos_den</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">tb</span><span class="p">[</span><span class="s">"true"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pos_recall</span> <span class="o">=</span> <span class="n">pos_num</span><span class="o">/</span><span class="n">pos_den</span>
    
    <span class="c1"># Get negative recall
</span>    <span class="n">neg_num</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">tb</span><span class="p">[</span><span class="s">"true"</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">tb_pred</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">neg_den</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">tb</span><span class="p">[</span><span class="s">"true"</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">neg_recall</span> <span class="o">=</span> <span class="n">neg_num</span><span class="o">/</span><span class="n">neg_den</span>
    
    <span class="c1"># Append accuracy, positive recall and negative
</span>    <span class="c1"># recall to empty lists
</span>    <span class="n">accuracies</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
    <span class="n">pos_recalls</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos_recall</span><span class="p">)</span>
    <span class="n">neg_recalls</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">neg_recall</span><span class="p">)</span>
    
<span class="c1"># Assemble metrics into a dataframe for convenient plotting
</span><span class="n">tb_results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">"Threshold"</span><span class="p">:</span><span class="n">thresholds</span><span class="p">,</span>
                           <span class="s">"Accuracy"</span><span class="p">:</span><span class="n">accuracies</span><span class="p">,</span>
                           <span class="s">"Recall (Pos)"</span><span class="p">:</span><span class="n">pos_recalls</span><span class="p">,</span>
                           <span class="s">"Recall (Neg)"</span><span class="p">:</span><span class="n">neg_recalls</span><span class="p">})</span>

<span class="c1"># Plot performance
</span><span class="n">tb_results_df</span><span class="p">.</span><span class="n">plot</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s">"TextBlob Performance"</span><span class="p">,</span>
                    <span class="n">x</span><span class="o">=</span><span class="s">"Threshold"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"upper left"</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="/projects/textblob-vs-tensorflow/output_20_0.png" alt="png" /></p>

<p>At a default threshold of 0, TextBlob catches almost all examples of positive reviews (+90%) but about 40% of negative reviews. Considering the importance of knowing when consumers aren’t pleased with their product, these parameters are not acceptable.</p>

<p>The most balanced results are around 0.10-0.20. At this specification, Accuracy and recall for both classes, positive and negative, are in the ballpark of 60-80%, and overall accuracy is 70%. We could micro-manage further and look at thresholds like 0.15, but there’s not much more value we’ll get out of this model that way.</p>

<p>At 70% accuracy, Textblob is just ok at guessing the sentiment of these reviews. In general it’s better at recognizing positive sentiment than negative.</p>

<h1 id="neural-network-experiments">Neural Network Experiments</h1>
<p>Now that a benchmark has been set by TextBlob, we’ll experiment with neural network models in TensorFlow to see if we can do better. We try 3 different optimizers (SGD, RMSProp, and ADAM) and 2 different activation functions for the hidden layer (Sigmoid, ReLu), or 6 different specifications.</p>

<p>Because these can take a considerable amount of time to train, only 10% of the data will be used while creating these 6 models, initially. They will be compared on the following aspects:</p>
<ul>
  <li><strong>Validation Accuracy</strong>: How well does the model predict out-of-sample?</li>
  <li><strong>Learning Potential</strong>: Can they become more accurate with more data/time?</li>
  <li><strong>Time to train</strong>: If two models have similar performance, is one more efficient?</li>
  <li><strong>Response Curve</strong>: Will test accuracy be strong regardless of the threshold?</li>
</ul>

<p>The best performing model out of these in terms of validation accuracy, learning potential, and time to train will be re-trained with all of the available data. This final model will then receive the same threshold examination as TextBlob.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define a function to retrieve a 10% sample of a pandas dataframe
</span><span class="k">def</span> <span class="nf">sample_tenth</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">data_sample</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                              <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">return</span><span class="p">(</span><span class="n">data_sample</span><span class="p">)</span>

<span class="c1"># Retrieve 10% sample
</span><span class="n">train_small</span> <span class="o">=</span> <span class="n">sample_tenth</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">valid_small</span> <span class="o">=</span> <span class="n">sample_tenth</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create list of specification combinations
</span><span class="n">activation_funs</span> <span class="o">=</span> <span class="p">[</span><span class="s">"sigmoid"</span><span class="p">,</span><span class="s">"relu"</span><span class="p">]</span>
<span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span><span class="s">"sgd"</span><span class="p">,</span><span class="s">"rmsprop"</span><span class="p">,</span><span class="s">"adam"</span><span class="p">]</span>
<span class="n">params</span> <span class="o">=</span> <span class="p">[(</span><span class="n">a</span><span class="p">,</span><span class="n">o</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">activation_funs</span>
                <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">]</span>

<span class="c1"># Create dictionary of activation function objects
</span><span class="n">activation_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s">"sigmoid"</span><span class="p">:</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">activations</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">,</span>
                   <span class="s">"relu"</span><span class="p">:</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">activations</span><span class="p">.</span><span class="n">relu</span><span class="p">}</span>
</code></pre></div></div>

<h2 id="the-text-embedding-model">The Text Embedding Model</h2>
<p><img src="assets/xzibit-happy-cropped.jpg" alt="yo dawg" width="40" height="40" style="float: right;" /> How do we transform text into numbers that a neural network can work with? Using a model known as <a href="https://tfhub.dev/google/nnlm-en-dim50-with-normalization/2">nnlm-en-dim50-with-normalization</a> hosted on TensorFlow Hub. I’m essentially putting a Neural Net inside the Neural Net as a layer.</p>

<p>This model normalizes a string of text by removing punctuation, then maps it to 50 dimensions for our Neural Net to ingest.</p>

<p>I create a Neural Net architecture with the text embedding model as the input layer, a dense hidden layer with 4 nodes, and finally a dense layer of 1 node to output the prediction value.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># If running on desktop, reset TensorFlow Hub's temporary 
# folder by deleting it, and letting the package recreate 
# it when calling KerasLayer to prevent errors
</span><span class="k">if</span> <span class="s">"TEMP"</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">tfhub_tempfolder</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">"TEMP"</span><span class="p">]</span> <span class="o">+</span> <span class="sa">r</span><span class="s">"//tfhub_modules"</span>

    <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">exists</span><span class="p">(</span><span class="n">tfhub_tempfolder</span><span class="p">):</span>
        <span class="n">shutil</span><span class="p">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">tfhub_tempfolder</span><span class="p">)</span>

<span class="c1"># Retrieve text embedding model from TensorFlow Hub        
</span><span class="n">model</span> <span class="o">=</span> <span class="s">"https://tfhub.dev/google/nnlm-en-dim50-with-normalization/2"</span>
<span class="n">hub_layer</span> <span class="o">=</span> <span class="n">hub</span><span class="p">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">[],</span> 
                           <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">string</span><span class="p">,</span> 
                           <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Assemble model architecture
</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">hub_layer</span><span class="p">,</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<h2 id="training-experimental-models">Training Experimental Models</h2>
<p>While the training is taking place, 3 objects are being saved to disk:</p>
<ul>
  <li>The model with parameters</li>
  <li>The weights that produced the highest validation accuracy (saved as a “checkpoint”)</li>
  <li>and the training history.</li>
</ul>

<p><strong>Why save to disk?</strong> Between 6 different neural net experiments and the final model fitting, this notebook will take several hours to complete. If there are any issues with the notebook or your computer after these models have been trained, you won’t have to retrain them. Instead you can pick up where you left off and the models will be loaded from disk.</p>

<p>These objects will be retrieved when evaluating how well each model performed. The file structure when the next cell finishes looks something like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>models
├───experimental
│   ├───{model-name1}
│   │       cp.ckpt
│   │       history.json
│   │       model.h5
│   │
│   ├───{model-name2}
│   │       [..]
[etc]
</code></pre></div></div>

<p>And now, using the 6 combinations of parameters and the model architecture previously defined, the models are trained:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create filepath for model outputs
</span><span class="n">exp_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s">"models/experimental/"</span>

<span class="c1"># Iterate over different parameters, creating
# a new neural net, training it, and saving it
# to distk
</span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    
    <span class="c1"># Get model name and create a filepath
</span>    <span class="n">model_name</span> <span class="o">=</span> <span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="s">"-"</span><span class="o">+</span><span class="n">param</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">model_path</span> <span class="o">=</span> <span class="n">exp_path</span> <span class="o">+</span> <span class="n">model_name</span> <span class="o">+</span> <span class="s">"/"</span>
    
    <span class="c1"># Designate an activation function to the hidden layer
</span>    <span class="n">model</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation_dict</span><span class="p">[</span><span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    
    <span class="c1"># Retrieve untrained weights, to use later to reset
</span>    <span class="c1"># model training
</span>    <span class="n">blank_weights</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">get_weights</span><span class="p">()</span>
    
    <span class="c1"># Compile model with this iteration's optimizer
</span>    <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">param</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                  <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span> 
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">BinaryAccuracy</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> 
                                                     <span class="n">name</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)])</span>
    
    <span class="c1"># Save model to disk
</span>    <span class="n">model</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_path</span><span class="o">+</span><span class="s">"model.h5"</span><span class="p">)</span>
    
    <span class="c1"># Create a checkpoint object which will automatically save the weights
</span>    <span class="c1"># with the highest validation accuracy as the model trains
</span>    <span class="n">cp_callback</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
        <span class="n">filepath</span><span class="o">=</span><span class="n">model_path</span><span class="o">+</span><span class="s">"cp.ckpt"</span><span class="p">,</span>
        <span class="n">save_weights_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s">"val_accuracy"</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s">"max"</span><span class="p">)</span>
    
    <span class="c1"># Train model
</span>    <span class="n">start</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_small</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span><span class="n">train_small</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">],</span>
                      <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                      <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">valid_small</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span> <span class="n">valid_small</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">]),</span>
                      <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">cp_callback</span><span class="p">])</span>
    
    <span class="n">stop</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
    
    <span class="c1"># Save training history to disk
</span>    <span class="n">history_dict</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span>
    <span class="n">history_dict</span><span class="p">[</span><span class="s">"time"</span><span class="p">]</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span> <span class="c1"># Add training time to history dictionary
</span>    
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_path</span> <span class="o">+</span> <span class="s">"history.json"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">history_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
        
    <span class="c1"># Use the untrained weights from before 
</span>    <span class="c1"># to reset the training process
</span>    <span class="n">model</span><span class="p">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">blank_weights</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  0%|          | 0/6 [00:00&lt;?, ?it/s]
</code></pre></div></div>

<h2 id="evaluate-models">Evaluate Models</h2>
<p>I retrieve the data from disk and create plots showing how the models performed in terms of loss and accuracy, for both training and validation sets.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Re-initialize the training history dictionary
</span><span class="n">history_dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># Read training histories from disk back into 
# the dictionary
</span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="s">"-"</span><span class="o">+</span><span class="n">param</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">history_path</span> <span class="o">=</span> <span class="n">exp_path</span> <span class="o">+</span> <span class="n">model_name</span> <span class="o">+</span> <span class="s">"/history.json"</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">history_path</span><span class="p">,</span> <span class="s">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">history_dict</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># For each model plot loss, accuracy, and
# print the training period
</span><span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">history_dict</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
    
    <span class="c1"># Get history object for this iteration's model
</span>    <span class="n">history</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
    
    <span class="c1"># Get training time
</span>    <span class="n">time</span> <span class="o">=</span> <span class="n">history</span><span class="p">[</span><span class="s">"time"</span><span class="p">]</span>
    
    <span class="c1"># Get the number of epochs for training
</span>    <span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s">"accuracy"</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Create figure and axes
</span>    <span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
    
    <span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">key</span><span class="p">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="se">\n</span><span class="s">Training Time: </span><span class="si">{</span><span class="n">time</span><span class="o">/</span><span class="mi">60</span><span class="si">:</span><span class="p">.</span><span class="mi">0</span><span class="n">f</span><span class="si">}</span><span class="s"> min"</span><span class="p">)</span>
    
    <span class="c1"># Plot loss
</span>    <span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">history</span><span class="p">[</span><span class="s">"loss"</span><span class="p">],</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Training Loss"</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">history</span><span class="p">[</span><span class="s">"val_loss"</span><span class="p">],</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Validation Loss"</span><span class="p">)</span>
    
    <span class="n">ax1</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="n">visible</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Epochs"</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Loss"</span><span class="p">)</span>
    <span class="n">ax1</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
    
    <span class="c1"># Plot accuracy
</span>    <span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">history</span><span class="p">[</span><span class="s">"accuracy"</span><span class="p">],</span> <span class="c1">#"b", 
</span>             <span class="n">label</span><span class="o">=</span><span class="s">"Training Accuracy"</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">history</span><span class="p">[</span><span class="s">"val_accuracy"</span><span class="p">],</span> <span class="c1">#"g", 
</span>             <span class="n">label</span><span class="o">=</span><span class="s">"Validation Accuracy"</span><span class="p">)</span>
    
    <span class="n">ax2</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="n">visible</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Epochs"</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Accuracy"</span><span class="p">)</span>
    <span class="n">ax2</span><span class="p">.</span><span class="n">legend</span><span class="p">();</span>
    
    
</code></pre></div></div>

<p><img src="/projects/textblob-vs-tensorflow/output_31_0.png" alt="png" /></p>

<p><img src="/projects/textblob-vs-tensorflow/output_31_1.png" alt="png" /></p>

<p><img src="/projects/textblob-vs-tensorflow/output_31_2.png" alt="png" /></p>

<p><img src="/projects/textblob-vs-tensorflow/output_31_3.png" alt="png" /></p>

<p><img src="/projects/textblob-vs-tensorflow/output_31_4.png" alt="png" /></p>

<p><img src="/projects/textblob-vs-tensorflow/output_31_5.png" alt="png" /></p>

<h2 id="validation-accuracy-learning-potential-and-time-to-train">Validation Accuracy, Learning Potential, and Time to Train.</h2>

<p>RMSProp and ADAM consistently reached their peak validation accuracy of 80-85% very quickly, regardless of activation function (Sigmoid or ReLu), then began to overfit. Both have strong validation accuracy, but very little learning potential. ADAM also took a bit longer than the other methods, a few minutes per model.</p>

<blockquote>
  <p>It’s worth noting that these were trained using the P100 GPU accelerator available when running this notebook on Kaggle. In earlier experiments on a PC with no acceleration, the differences in time were much more pronounced: SGD consistently took less than 10 minutes, RMSProp consistently took over 20, and ADAM over 45 minutes to complete training.</p>
</blockquote>

<p>SGD had comparable validation accuracy to the other optimizers (70-80%) while showing the best potential for even better accuracy. Unlike the others, both validation and training accuracy continued to rise together until the end of the training period, suggesting that it will improve if given more time and training data.</p>

<p>SGD with either activation function showed the highest accuracy, so we will compare the different activation functions with a response curve to explore how our final output threshold might affect results.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define function to load a saved Neural Net model 
# and its weights, then use to make predictions based on data X
</span><span class="k">def</span> <span class="nf">load_nn_and_predict</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span>
        <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span><span class="s">"model.h5"</span><span class="p">),</span>
        <span class="n">custom_objects</span><span class="o">=</span><span class="p">{</span><span class="s">"KerasLayer"</span><span class="p">:</span><span class="n">hub</span><span class="p">.</span><span class="n">KerasLayer</span><span class="p">})</span>

    <span class="n">model</span><span class="p">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s">"cp.ckpt"</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    
    <span class="k">return</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

<span class="c1"># Load SGD/Sigmoid and SGD/Relu models and 
# predict polarity for test set
</span><span class="n">sigmoid_pred</span> <span class="o">=</span> <span class="n">load_nn_and_predict</span><span class="p">(</span><span class="n">exp_path</span> <span class="o">+</span> <span class="s">"/sigmoid-sgd/"</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="s">"text"</span><span class="p">])</span>
<span class="n">relu_pred</span> <span class="o">=</span> <span class="n">load_nn_and_predict</span><span class="p">(</span><span class="n">exp_path</span> <span class="o">+</span> <span class="s">"/relu-sgd/"</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="s">"text"</span><span class="p">])</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12500/12500 [==============================] - 46s 4ms/step
12500/12500 [==============================] - 46s 4ms/step
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define function to generate and plot ROC curve
</span><span class="k">def</span> <span class="nf">plot_nn_roc_curve</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

    <span class="n">auc_score</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

    <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"AUC Area = </span><span class="si">{</span><span class="n">auc_score</span><span class="si">:</span><span class="p">.</span><span class="mi">5</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">"--"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"False Positive Rate"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"True Positive Rate"</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"lower right"</span><span class="p">);</span>


<span class="c1"># Create figure and axes
</span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s">"ROC Curves"</span><span class="p">)</span>

<span class="c1"># Plot ROC curves for SGD/Sigmoid and SGD/ReLu
</span><span class="n">plot_nn_roc_curve</span><span class="p">(</span><span class="s">"Sigmoid"</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">],</span> <span class="n">sigmoid_pred</span><span class="p">,</span> <span class="n">ax1</span><span class="p">)</span>
<span class="n">plot_nn_roc_curve</span><span class="p">(</span><span class="s">"ReLu"</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">],</span> <span class="n">relu_pred</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span>

</code></pre></div></div>

<p><img src="/projects/textblob-vs-tensorflow/output_34_0.png" alt="png" /></p>

<p>The ROC, or Response Object Curve, shows the trade-offs between a high True Positive rate and a False Positive rate depending on your threshold. The area under the curve is an overall measure of the precision of the model regardless of threshold. ReLu has a slight edge over Sigmoid in this respect.</p>

<p>Out of the 6 models attempted, using SGD as the optimizer and ReLu as the activation function in the intermediate layers has relatively high validation accuracy, the highest potential accuracy while being efficient, and is also the best independent from the output threshold we determine.</p>

<p>This is the specification we will use in the final model, where all the data will be used for training.</p>

<h1 id="final-model">Final Model</h1>
<p>It’s the home stretch! Here’s what’s being done in the following code in plain English:</p>
<ul>
  <li>Retrieve the saved model specifications with ReLu activation in the hidden layer and SGD as the optimizer.</li>
  <li>Train it on the full dataset</li>
  <li>Save the model, weights, and training history to disk</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Specify path where preferred model is saved
</span><span class="n">relu_sgd_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s">"models/experimental/relu-sgd/"</span>

<span class="c1"># Define new path for final model
</span><span class="n">final_model_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s">"models/final/"</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load neural network model architecture
# for SGD/ReLu
</span><span class="k">print</span><span class="p">(</span><span class="s">"Loading model"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span>
    <span class="sa">r</span><span class="s">"models/experimental/relu-sgd/model.h5"</span><span class="p">,</span>
    <span class="n">custom_objects</span><span class="o">=</span><span class="p">{</span><span class="s">"KerasLayer"</span><span class="p">:</span><span class="n">hub</span><span class="p">.</span><span class="n">KerasLayer</span><span class="p">})</span>

<span class="c1"># Save this model to the "final" model folder
</span><span class="n">model</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">final_model_path</span><span class="o">+</span><span class="s">"model.h5"</span><span class="p">)</span>

<span class="c1"># Create a checkpoint object which will automatically save the weights
# with the highest validation accuracy as the model trains
</span><span class="k">print</span><span class="p">(</span><span class="s">"Creating checkpoint object"</span><span class="p">)</span>
<span class="n">cp_callback</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
    <span class="n">filepath</span><span class="o">=</span><span class="n">final_model_path</span><span class="o">+</span><span class="s">"cp.ckpt"</span><span class="p">,</span>
    <span class="n">save_weights_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s">"val_accuracy"</span><span class="p">,</span><span class="n">mode</span><span class="o">=</span><span class="s">"max"</span><span class="p">)</span>

<span class="c1"># Train Model
</span><span class="k">print</span><span class="p">(</span><span class="s">"Training Model"</span><span class="p">)</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span><span class="n">train</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">],</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">valid</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">]),</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">cp_callback</span><span class="p">])</span>
<span class="n">stop</span> <span class="o">=</span> <span class="n">timeit</span><span class="p">.</span><span class="n">default_timer</span><span class="p">()</span>

<span class="c1"># Save training history
</span><span class="k">print</span><span class="p">(</span><span class="s">"Saving training history"</span><span class="p">)</span>
<span class="n">history_dict</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span>
<span class="n">history_dict</span><span class="p">[</span><span class="s">"time"</span><span class="p">]</span> <span class="o">=</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span> <span class="c1"># Add training time to history dictionary
</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">final_model_path</span> <span class="o">+</span> <span class="s">"history.json"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">history_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    
<span class="k">print</span><span class="p">(</span><span class="s">"Done"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Loading model
Creating checkpoint object
Training Model
Saving training history
Done
</code></pre></div></div>

<h1 id="evaluate-final-model">Evaluate Final Model</h1>
<p>Similar to before, I retrieve the model, weights and history from disk and examine its performance.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Read training histories for the final model
# into the dictionary
</span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">final_model_path</span> <span class="o">+</span> <span class="s">"history.json"</span><span class="p">,</span> <span class="s">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">history_dict</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Get training time
</span><span class="n">time</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s">"time"</span><span class="p">]</span>

<span class="c1"># Get the number of epochs for training
</span><span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">history_dict</span><span class="p">[</span><span class="s">"accuracy"</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

 <span class="c1"># Create figure and axes
</span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s">"Sigmoid-SGD</span><span class="se">\n</span><span class="s">Hours of Training: </span><span class="si">{</span><span class="n">time</span><span class="o">/</span><span class="mi">60</span><span class="o">/</span><span class="mi">60</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="c1"># Plot loss
</span><span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">history_dict</span><span class="p">[</span><span class="s">"loss"</span><span class="p">],</span> <span class="s">"b"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Training Loss"</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">history_dict</span><span class="p">[</span><span class="s">"val_loss"</span><span class="p">],</span> <span class="s">"g"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Validation Loss"</span><span class="p">)</span>

<span class="n">ax1</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="n">visible</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Epochs"</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Loss"</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Plot accuracy
</span><span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">history_dict</span><span class="p">[</span><span class="s">"accuracy"</span><span class="p">],</span> <span class="s">"b"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Training Accuracy"</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">history_dict</span><span class="p">[</span><span class="s">"val_accuracy"</span><span class="p">],</span> <span class="s">"g"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Validation Accuracy"</span><span class="p">)</span>

<span class="n">ax2</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="n">visible</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Epochs"</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Accuracy"</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">legend</span><span class="p">();</span>
</code></pre></div></div>

<p><img src="/projects/textblob-vs-tensorflow/output_41_0.png" alt="png" /></p>

<p>While training and validation accuracy never diverged (the model was not overfit) it started to plateau around 90%. It’s unlikely the model would significantly exceed this figure with a longer training period.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Load model and weights, then make predictions using the test set
</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">final_model_path</span><span class="o">+</span><span class="s">"model.h5"</span><span class="p">,</span>
                                   <span class="n">custom_objects</span><span class="o">=</span><span class="p">{</span><span class="s">"KerasLayer"</span><span class="p">:</span><span class="n">hub</span><span class="p">.</span><span class="n">KerasLayer</span><span class="p">})</span>

<span class="n">model</span><span class="p">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">final_model_path</span><span class="o">+</span><span class="s">"cp.ckpt"</span><span class="p">)</span>

<span class="n">prob</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">"text"</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12500/12500 [==============================] - 46s 4ms/step
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot ROC Curve
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">roc_curve</span><span class="p">(</span>
                        <span class="n">test</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">],</span> <span class="n">prob</span><span class="p">)</span>

<span class="n">auc_score</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"AUC Area = </span><span class="si">{</span><span class="n">auc_score</span><span class="si">:</span><span class="p">.</span><span class="mi">5</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">"--"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"RELU-SGD"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"False Positive Rate"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"True Positive Rate"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"lower right"</span><span class="p">);</span>

</code></pre></div></div>

<p><img src="/projects/textblob-vs-tensorflow/output_44_0.png" alt="png" /></p>

<p>The area under the response curve is slightly higher, so overall our model is performing better with more data to train on.</p>

<p>Next, we’re going to see how accuracy and recall for both classes change with different thresholds. But first, a quick transformation will be applied to make the output probabilities more practical to interpret.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Print minimum and maximum outputs from the neural network
</span><span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">prob</span><span class="p">.</span><span class="n">ravel</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">prob</span><span class="p">.</span><span class="n">ravel</span><span class="p">()))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>-34.466152
15.068687
</code></pre></div></div>

<p>Above is the minimum and maximum polarity output by our model. I’ll use a sigmoid function to coelesce these figures to between 0 and 1</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define function to apply sigmoid function to a number
</span><span class="k">def</span> <span class="nf">sigmoid_fun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)))</span>

<span class="c1"># Apply sigmoid function to neural network output
</span><span class="n">prob_sigmoid</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">prob</span><span class="p">.</span><span class="n">ravel</span><span class="p">()).</span><span class="nb">apply</span><span class="p">(</span><span class="n">sigmoid_fun</span><span class="p">)</span>
</code></pre></div></div>

<p>And now I compare metrics across different thresholds</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create numpy array of thresholds
</span><span class="n">thresholds</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.01</span><span class="p">,</span><span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">).</span><span class="nb">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Initialize empty lists for accuracy,
# positive class recall and negative 
# class recall
</span><span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">pos_recalls</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">neg_recalls</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Using a loop, populate empty lists
</span><span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="p">:</span>
    <span class="c1"># Get prediction conditional on threshold
</span>    <span class="n">tf_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">prob_sigmoid</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">).</span><span class="n">ravel</span><span class="p">()</span>
    
    <span class="c1"># Get difference between prediction and ground truth
</span>    <span class="c1"># Where difference == 0, the prediction was accurate
</span>    <span class="n">difference</span> <span class="o">=</span> <span class="n">tf_pred</span> <span class="o">-</span> <span class="n">test</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">]</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">difference</span><span class="p">.</span><span class="n">value_counts</span><span class="p">()</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Get positive recall
</span>    <span class="n">pos_num</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">test</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">tf_pred</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">pos_den</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pos_recall</span> <span class="o">=</span> <span class="n">pos_num</span><span class="o">/</span><span class="n">pos_den</span>

    <span class="c1"># Get negative recall
</span>    <span class="n">neg_num</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">test</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">tf_pred</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">neg_den</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s">"polarity"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">neg_recall</span> <span class="o">=</span> <span class="n">neg_num</span><span class="o">/</span><span class="n">neg_den</span>
    
    <span class="c1"># Append accuracy, positive recall and negative
</span>    <span class="c1"># recall to empty lists
</span>    <span class="n">accuracies</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
    <span class="n">pos_recalls</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos_recall</span><span class="p">)</span>
    <span class="n">neg_recalls</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">neg_recall</span><span class="p">)</span>

<span class="c1"># Assemble metrics into a dataframe for convenient plotting
</span><span class="n">tf_results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">"Threshold"</span><span class="p">:</span><span class="n">thresholds</span><span class="p">,</span>
                           <span class="s">"Accuracy"</span><span class="p">:</span><span class="n">accuracies</span><span class="p">,</span>
                           <span class="s">"Recall (1)"</span><span class="p">:</span><span class="n">pos_recalls</span><span class="p">,</span>
                           <span class="s">"Recall (0)"</span><span class="p">:</span><span class="n">neg_recalls</span><span class="p">})</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot TensorFlow performance
</span><span class="n">tf_results_df</span><span class="p">.</span><span class="n">plot</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"Threshold"</span><span class="p">,</span>
                       <span class="n">title</span><span class="o">=</span><span class="s">"TensorFlow Neural Network Performance"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"upper left"</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="/projects/textblob-vs-tensorflow/output_51_0.png" alt="png" /></p>

<p>The most balanced result is at 0.5, so I’ll print out the exact metrics when this threshold is chosen.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Print TensorFlow metrics at threshold == 0.5
</span><span class="n">display</span><span class="p">(</span><span class="n">tf_results_df</span><span class="p">[</span><span class="n">tf_results_df</span><span class="p">[</span><span class="s">"Threshold"</span><span class="p">]</span><span class="o">==</span><span class="mf">0.5</span><span class="p">])</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Threshold</th>
      <th>Accuracy</th>
      <th>Recall (1)</th>
      <th>Recall (0)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>0.5</td>
      <td>0.88874</td>
      <td>0.888305</td>
      <td>0.889175</td>
    </tr>
  </tbody>
</table>
</div>

<p>To make it easier to remember, here’s the same plot but for TextBlob predictions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Plot TextBlob performance
</span><span class="n">tb_results_df</span><span class="p">.</span><span class="n">plot</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s">"TextBlob Sentiment Analysis Performance"</span><span class="p">,</span>
                    <span class="n">x</span><span class="o">=</span><span class="s">"Threshold"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"upper left"</span><span class="p">);</span>
</code></pre></div></div>

<p><img src="/projects/textblob-vs-tensorflow/output_55_0.png" alt="png" /></p>

<p>Once again, the most balanced results were around 0.10-0.20, so I’ll print out the exact metrics for these two thresholds.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Print TextBlob metrics at threshold == 0.1 and 0.2
</span><span class="n">display</span><span class="p">(</span><span class="n">tb_results_df</span><span class="p">[</span><span class="n">tb_results_df</span><span class="p">[</span><span class="s">"Threshold"</span><span class="p">]</span><span class="o">==</span><span class="mf">0.1</span><span class="p">])</span>
<span class="n">display</span><span class="p">(</span><span class="n">tb_results_df</span><span class="p">[</span><span class="n">tb_results_df</span><span class="p">[</span><span class="s">"Threshold"</span><span class="p">]</span><span class="o">==</span><span class="mf">0.2</span><span class="p">])</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Threshold</th>
      <th>Accuracy</th>
      <th>Recall (Pos)</th>
      <th>Recall (Neg)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6</th>
      <td>0.1</td>
      <td>0.723633</td>
      <td>0.82407</td>
      <td>0.623195</td>
    </tr>
  </tbody>
</table>
</div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Threshold</th>
      <th>Accuracy</th>
      <th>Recall (Pos)</th>
      <th>Recall (Neg)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>7</th>
      <td>0.2</td>
      <td>0.722538</td>
      <td>0.628305</td>
      <td>0.81677</td>
    </tr>
  </tbody>
</table>
</div>

<h1 id="final-verdict">Final Verdict</h1>
<p>With some overnight tuning, the final model predicts whether the text of an amazon review reflects a positive or negative sentiment, and is correct 88% percent of the time. The epoch-by-epoch trend suggests that the model was approaching its peak out of sample accuracy, and likely would not go higher than 90%. This is still significantly better than Textblob, which had 75% accuracy and similar recall for both positive and negative sentiment.</p>

<p>With a single day of experimentation to arrive at a stronger neural network specification and training using Kaggle’s GPU acceleration, a relatively simple neural net can outperform TextBlob by about 15% in terms of accuracy, if you have specific data to train on for the task at hand.</p>

<ul>
  <li>Replicate this <a href="https://www.kaggle.com/code/kfoster150/textblob-vs-tensorflow-for-sentiment-analysis">here</a></li>
  <li>Check out the dataset <a href="https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews">here</a></li>
  <li>Read the original course report <a href="https://github.com/ken-foster/ken-foster.github.io/raw/main/files/Textblob%20vs%20TensorFlow.pdf" download="">here</a></li>
</ul>

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Home</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Home</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/ken-foster"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">ken-foster</span></a></li><li><a href="https://www.linkedin.com/in/kennethbfoster"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">kennethbfoster</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A portfolio website for Kenneth Foster
</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
